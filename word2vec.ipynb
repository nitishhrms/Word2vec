{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 5)\n",
      "[['elephant' 'lion' 'tiger' 'goat' 'snake']\n",
      " ['man' 'policeman' 'fireman' 'teacher' 'postman']\n",
      " ['plane' 'bird' 'rocket' 'balloon' 'cat']\n",
      " ['onion' 'celery' 'lettuce' 'pineapple' 'potato']\n",
      " ['India' 'football' 'hockey' 'cricket' 'swimming']\n",
      " ['who' 'why' 'what' 'where' 'is']\n",
      " ['on' 'in' 'over' 'their' 'was']\n",
      " ['India' 'Australia' 'Japan' 'Russia' 'China']\n",
      " ['Dollar' 'Rupees' 'Euros' 'Cents' 'Money']\n",
      " ['eat' 'sleep' 'drink' 'think' 'dance']\n",
      " ['car' 'scooter' 'bike' 'bicycle' 'ship']\n",
      " ['Poland' 'Russia' 'England' 'Rome' 'Ukraine']\n",
      " ['Lake' 'Sea' 'River' 'Pool' 'Pond']\n",
      " ['Sun' 'Moon' 'Star' 'Mars' 'Egypt']\n",
      " ['fox' 'wolf' 'jackal' 'mouse' 'panther']\n",
      " ['veil' 'turban' 'helmet' 'shirt' 'hat']\n",
      " ['Physics' 'Chemistry' 'Geography' 'Botany' 'Universe']\n",
      " ['Assassinate' 'Kill' 'Kidnap' 'Stab' 'Murder']\n",
      " ['Hostel' 'Hotel' 'Inn' 'Club' 'Motel']\n",
      " ['Earth' 'Mars' 'Neptune' 'Pluto' 'Sun']]\n"
     ]
    }
   ],
   "source": [
    "dfx=pd.read_csv(\"odd one test.csv\")\n",
    "X=dfx.values\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1=['apple','mango','banana','party']\n",
    "input_2=['her','she','his','girl']\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57518554]]\n",
      "[[0.42481446]]\n"
     ]
    }
   ],
   "source": [
    "v_apple=word_vectors['apple']\n",
    "v_mango=word_vectors['mango']\n",
    "print(cosine_similarity([v_apple],[v_mango]))\n",
    "print(cosine_distances([v_apple],[v_mango]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    all_word_vectors=[word_vectors[w] for w in words]\n",
    "    avg_vector=np.mean(all_word_vectors,axis=0)\n",
    "    #print(avg_vector.shape)\n",
    "    \n",
    "    odd_one_out=None\n",
    "    min_sim=1.0\n",
    "    for w in words:\n",
    "        sim=cosine_similarity([word_vectors[w]],[avg_vector])\n",
    "        print('Similarity between %s and average vector is %.2f' %(w,sim))\n",
    "        if sim<min_sim:\n",
    "            min_sim=sim\n",
    "            odd_one=w\n",
    "    return odd_one        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between her and average vector is 0.91\n",
      "Similarity between she and average vector is 0.84\n",
      "Similarity between his and average vector is 0.64\n",
      "Similarity between girl and average vector is 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'his'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between elephant and average vector is 0.84\n",
      "Similarity between lion and average vector is 0.74\n",
      "Similarity between tiger and average vector is 0.83\n",
      "Similarity between goat and average vector is 0.73\n",
      "Similarity between snake and average vector is 0.73\n",
      "Similarity between man and average vector is 0.68\n",
      "Similarity between policeman and average vector is 0.80\n",
      "Similarity between fireman and average vector is 0.77\n",
      "Similarity between teacher and average vector is 0.61\n",
      "Similarity between postman and average vector is 0.75\n",
      "Similarity between plane and average vector is 0.66\n",
      "Similarity between bird and average vector is 0.67\n",
      "Similarity between rocket and average vector is 0.59\n",
      "Similarity between balloon and average vector is 0.68\n",
      "Similarity between cat and average vector is 0.58\n",
      "Similarity between onion and average vector is 0.83\n",
      "Similarity between celery and average vector is 0.84\n",
      "Similarity between lettuce and average vector is 0.83\n",
      "Similarity between pineapple and average vector is 0.77\n",
      "Similarity between potato and average vector is 0.82\n",
      "Similarity between India and average vector is 0.41\n",
      "Similarity between football and average vector is 0.70\n",
      "Similarity between hockey and average vector is 0.76\n",
      "Similarity between cricket and average vector is 0.80\n",
      "Similarity between swimming and average vector is 0.57\n",
      "Similarity between who and average vector is 0.54\n",
      "Similarity between why and average vector is 0.81\n",
      "Similarity between what and average vector is 0.79\n",
      "Similarity between where and average vector is 0.67\n",
      "Similarity between is and average vector is 0.47\n",
      "Similarity between on and average vector is 0.66\n",
      "Similarity between in and average vector is 0.72\n",
      "Similarity between over and average vector is 0.64\n",
      "Similarity between their and average vector is 0.60\n",
      "Similarity between was and average vector is 0.54\n",
      "Similarity between India and average vector is 0.79\n",
      "Similarity between Australia and average vector is 0.71\n",
      "Similarity between Japan and average vector is 0.79\n",
      "Similarity between Russia and average vector is 0.74\n",
      "Similarity between China and average vector is 0.82\n",
      "Similarity between Dollar and average vector is 0.69\n",
      "Similarity between Rupees and average vector is 0.72\n",
      "Similarity between Euros and average vector is 0.62\n",
      "Similarity between Cents and average vector is 0.66\n",
      "Similarity between Money and average vector is 0.55\n",
      "Similarity between eat and average vector is 0.76\n",
      "Similarity between sleep and average vector is 0.69\n",
      "Similarity between drink and average vector is 0.73\n",
      "Similarity between think and average vector is 0.48\n",
      "Similarity between dance and average vector is 0.55\n",
      "Similarity between car and average vector is 0.77\n",
      "Similarity between scooter and average vector is 0.87\n",
      "Similarity between bike and average vector is 0.88\n",
      "Similarity between bicycle and average vector is 0.86\n",
      "Similarity between ship and average vector is 0.39\n",
      "Similarity between Poland and average vector is 0.80\n",
      "Similarity between Russia and average vector is 0.82\n",
      "Similarity between England and average vector is 0.57\n",
      "Similarity between Rome and average vector is 0.54\n",
      "Similarity between Ukraine and average vector is 0.83\n",
      "Similarity between Lake and average vector is 0.76\n",
      "Similarity between Sea and average vector is 0.60\n",
      "Similarity between River and average vector is 0.75\n",
      "Similarity between Pool and average vector is 0.54\n",
      "Similarity between Pond and average vector is 0.73\n",
      "Similarity between Sun and average vector is 0.71\n",
      "Similarity between Moon and average vector is 0.70\n",
      "Similarity between Star and average vector is 0.59\n",
      "Similarity between Mars and average vector is 0.65\n",
      "Similarity between Egypt and average vector is 0.41\n",
      "Similarity between fox and average vector is 0.80\n",
      "Similarity between wolf and average vector is 0.79\n",
      "Similarity between jackal and average vector is 0.69\n",
      "Similarity between mouse and average vector is 0.58\n",
      "Similarity between panther and average vector is 0.76\n",
      "Similarity between veil and average vector is 0.71\n",
      "Similarity between turban and average vector is 0.76\n",
      "Similarity between helmet and average vector is 0.69\n",
      "Similarity between shirt and average vector is 0.70\n",
      "Similarity between hat and average vector is 0.73\n",
      "Similarity between Physics and average vector is 0.83\n",
      "Similarity between Chemistry and average vector is 0.77\n",
      "Similarity between Geography and average vector is 0.73\n",
      "Similarity between Botany and average vector is 0.66\n",
      "Similarity between Universe and average vector is 0.57\n",
      "Similarity between Assassinate and average vector is 0.69\n",
      "Similarity between Kill and average vector is 0.68\n",
      "Similarity between Kidnap and average vector is 0.74\n",
      "Similarity between Stab and average vector is 0.70\n",
      "Similarity between Murder and average vector is 0.74\n",
      "Similarity between Hostel and average vector is 0.63\n",
      "Similarity between Hotel and average vector is 0.82\n",
      "Similarity between Inn and average vector is 0.86\n",
      "Similarity between Club and average vector is 0.58\n",
      "Similarity between Motel and average vector is 0.81\n",
      "Similarity between Earth and average vector is 0.74\n",
      "Similarity between Mars and average vector is 0.78\n",
      "Similarity between Neptune and average vector is 0.67\n",
      "Similarity between Pluto and average vector is 0.75\n",
      "Similarity between Sun and average vector is 0.54\n",
      "['snake', 'teacher', 'cat', 'pineapple', 'India', 'is', 'was', 'Australia', 'Money', 'think', 'ship', 'Rome', 'Pool', 'Egypt', 'mouse', 'helmet', 'Universe', 'Kill', 'Club', 'Sun']\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for ix in range(20):\n",
    "    y.append(odd_one_out(X[ix]))\n",
    "print(y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y,columns=[\"oddone\"])\n",
    "pred.to_csv(\"oddonechallenge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the wrod analogies\n",
    "def predict_word(a,b,c,word_vectors):\n",
    "    a,b,c=a.lower(),b.lower(),c.lower()\n",
    "    max_similarity=-100\n",
    "    d=None\n",
    "    words=word_vectors.vocab.keys()\n",
    "    wa,wb,wc=word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    \n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        wv=word_vectors[w]\n",
    "        sim=cosine_similarity([wb-wa],[wv-wc])\n",
    "        if sim>max_similarity:\n",
    "            max_similarity=sim\n",
    "            d=w\n",
    "    return d        \n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True,limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'princess'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad_2=(\"man\",\"woman\",\"prince\")\n",
    "predict_word(\"man\",\"woman\",\"prince\",word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman','king'],negative=['man'],topn=1)\n",
    "#word_vectors.doesnt_match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\xbfthe', 'ace', 'tennis', 'star', 'sania', 'mirza', 'left', 'everyone', 'surprised', 'decided', 'tie', 'knot', 'pakistani', 'cricketer', 'named', 'shoaib', 'malik'], ['the', 'couple', 'tied', 'knot', '2010', 'expecting', 'first', 'child', 'months'], ['sania', 'shoaib', 'met', 'restaurant', 'later', 'shoaib', 'came', 'see', 'match'], ['soon', 'two', 'became', 'friends', 'fell', 'love'], ['bollywood', 'power', 'couple', 'aishwarya', 'rai', 'bachchan', 'abhishek', 'bachchan', 'recently', 'paid', 'visit', 'mangalore', 'family', 'ritual'], ['aishwarya', 'looked', 'beautiful', 'ice', 'blue', 'indian', 'ensemble', 'abhishek', 'kept', 'opted', 'white', 'kurta-pyjama', 'red', 'waistcoat'], ['the', 'beauty', 'completed', 'look', 'sleek', 'hair', 'bold', 'red', 'lips'], ['the', 'duo', 'accompanied', 'aishwarya', 'mother', 'vrinda', 'rai'], ['reportedly', 'couple', 'mangalore', 'aishwarya', 'uncle', \"'vaikuntha\", 'samaradhane', 'ritual', 'kadri', 'manjunatheshwara', 'temple', 'hall'], ['her', 'uncle', 'took', 'last', 'breath', 'recently'], ['meanwhile', 'work', 'front', 'abhishek', 'last', 'seen', \"'manmarziyaan\", 'next', 'feature', 'anurag', 'basu', 'directorial'], ['hand', 'ash', 'last', 'seen', 'anil', 'kapoor', 'rajkummar', 'rao', 'starrer', \"'fanney\", 'khan'], ['ranveer', 'singh', 'always', 'open', 'expressive', 'love', 'beautiful', 'wife', 'deepika', 'padukone'], ['the', 'couple', 'tied', 'knot', 'last', 'year', 'painting', 'town', 'red', 'ever', 'since', 'giving', 'everyone', 'major', 'couple', 'goals'], ['after', 'dating', 'six', 'seven', 'years', 'deepika', 'padukone', 'ranveer', 'singh', 'made', 'relationship', 'official', 'getting', 'married', 'presence', 'family', 'loved', 'ones'], ['she', 'recently', 'opened', 'decision', 'get', 'hitched', 'settle', 'peak', 'career'], ['speaking', 'reportedly', 'said', 'ranveer', 'brought', 'way', 'family', 'extremely', 'important'], ['she', 'stated', 'outside', 'look', 'like', 'completely', 'different', 'people', 'core', 'feels', 'exactly'], ['elaborating', 'added', 'moved', 'home', 'young', 'age']]\n"
     ]
    }
   ],
   "source": [
    "##word2vec interesting project\n",
    "#sw=set(stopwords.words('english'))\n",
    "def readfile(file):\n",
    "    sw=set(stopwords.words('english'))\n",
    "    f=open(file,'r')\n",
    "    text1=f.read()\n",
    "    \n",
    "    \n",
    "    \n",
    "    sentences=nltk.sent_tokenize(text1)\n",
    "    data=[]\n",
    "#print(sentences)\n",
    "    for sent in sentences:\n",
    "        word_1=nltk.word_tokenize(sent)\n",
    "        word_1=[w.lower() for w in word_1 if len(w)>2 and w not in sw]\n",
    "        data.append(word_1)\n",
    "    return data\n",
    "text=readfile('word2vectextfile.txt')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=161, size=400, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model=Word2Vec(text,size=400,window=10,min_count=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['six', 'kadri', 'deepika', 'named', 'years', 'mirza', 'young', '2010', 'surprised', 'anil', 'get', 'couple', 'soon', 'feels', 'ones', 'sania', 'knot', 'front', 'sleek', 'bollywood', 'hall', 'like', 'always', 'married', 'starrer', 'settle', 'she', 'accompanied', 'ranveer', 'everyone', 'people', 'hair', 'lips', 'decided', \"'vaikuntha\", 'year', 'home', 'expressive', 'cricketer', 'blue', 'kapoor', 'said', 'opted', 'shoaib', 'kurta-pyjama', 'decision', 'since', 'ice', 'outside', 'indian', 'dating', 'ever', 'temple', 'red', 'core', 'basu', 'recently', 'bold', 'vrinda', 'met', 'completely', 'paid', 'ash', 'manjunatheshwara', 'last', 'her', 'ace', 'getting', 'career', 'ritual', 'bachchan', 'samaradhane', 'became', 'expecting', 'aishwarya', 'fell', 'first', 'major', 'love', 'elaborating', 'family', 'presence', \"'manmarziyaan\", 'brought', 'open', 'khan', 'anurag', 'duo', 'friends', 'tennis', 'visit', 'two', 'next', 'breath', 'way', '\\xbfthe', 'white', 'pakistani', 'speaking', 'waistcoat', 'relationship', 'beauty', 'completed', 'exactly', 'took', 'uncle', 'goals', 'child', 'abhishek', 'town', 'loved', 'made', 'look', 'rajkummar', 'restaurant', \"'fanney\", 'directorial', 'match', 'malik', 'mangalore', 'beautiful', 'seven', 'months', 'stated', 'rao', 'official', 'moved', 'rai', 'padukone', 'seen', 'work', 'different', 'meanwhile', 'feature', 'power', 'see', 'tie', 'singh', 'ensemble', 'added', 'star', 'reportedly', 'after', 'tied', 'hand', 'hitched', 'important', 'peak', 'extremely', 'opened', 'kept', 'wife', 'age', 'later', 'looked', 'giving', 'mother', 'the', 'painting', 'came', 'left']\n"
     ]
    }
   ],
   "source": [
    "words=list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_actor(a,b,c,word_vectors):\n",
    "    a,b,c=a.lower(),b.lower(),c.lower()\n",
    "    wa,wb,wc=word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    options=['ranveer','deepika','padukone','singh','sania','mirza','shoaib','malik']\n",
    "    d=None\n",
    "    max_sim=-100\n",
    "    for w in options:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        wv=word_vectors[w]    \n",
    "        sim=cosine_similarity([wb-wa],[wv-wc])\n",
    "        if sim>max_sim:\n",
    "            max_sim=sim\n",
    "            d=w\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'malik'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#triad=('ranveer','singh','deepika')\n",
    "predict_actor('ranveer','singh','shoaib',model.wv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
